{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Les 1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heuristics:</br>\n",
    "</br>\n",
    "A heuristic technique, often called simply a heuristic, is any approachto problem solving, learning, or discovery that employs a practical methodnot guaranteed to be optimal or perfect, but sufficient for the immediate goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent:</br>\n",
    "</br>\n",
    "It is an optimization algorithm to find the minimum of a function.</br>\n",
    "Start with a random point on the function and move in the negative direction of the function to reach the local/global minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gentic Algorithm: </br>\n",
    "<br>\n",
    "A genetic algorithm maintains a population of candidate solutions for the optimization problem to solve, and makes it evolveby iteratively applying a set of stochastic operators(selection, crossover, mutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ga.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Pros:</br> \n",
    "x Less likely to get stuck in local extreme than other methods.</br> \n",
    "x Effective heuristic when dealing with a very large solution space.</br>\n",
    "x Easy to implement.</br>\n",
    "-Cons:</br> \n",
    "x Choosing encoding and fitness function can be difficult</br>\n",
    "x Computational time (but they can be parallelized)</br>\n",
    "-Uses:</br>Difficult problems (such as NP-hard problems); machine learning; for evolving simple programs; predicting, data analysis, designing neural networks, evolving LISP programs, strategy planning, finding shape of protein molecules, TSP and sequence scheduling, functions for creating images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Les 2</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of Machine Learning:\n",
    "- Supervised: Data points have known outcome</br>\n",
    "x Regression: Outcome is continuous</br>\n",
    "x Classification: Outcome is categorical</br>\n",
    "- Unsupervised: Data points have unknown outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning Overview:\n",
    "- Data with answers + model -> fit -> Model\n",
    "- Data without answers + Model -> predict -> predicted answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Supervised-Learning-versus-Unsupervised-Learning-Mathworks-nd.png\"><img src=\"616b63f3b531b95ff6a35dea_data-in-supervised-vs-unsupervised-cover.png\" width=400 height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine vocabulary: \n",
    "- Target: Predicted category or value of data(column to predict)\n",
    "- Features: Properties of data used for prediction(non target columns)\n",
    "- Example: A single data point within the data(one row)\n",
    "- Label: The target value for a single data point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is needed for classification?:\n",
    "- Model data with:</br>\n",
    "x Features that can be quantitated</br>\n",
    "x Labels that are known</br>\n",
    "- Method to measure similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest classification\n",
    "-predicts label by looking at nearest node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is needed to select a knn model?\n",
    "-correct value for k\n",
    "-boundary decision (grens voor bepalen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling\n",
    "- Normalization: Helps scaling feature between 0-1</br>\n",
    "x Min-Max Scaling: A formula which helps with normalization scaling; Helps scaling feature between 0-1.</br>\n",
    "x Maximum absolute value scaler: Scale maximum absolute value</br>\n",
    "x Standard scaler: Mean center data and scale to unit variance</br>\n",
    "- Standardization: Helps scaling with standard normal distrubution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN:\n",
    "- Euclidian Distance: Measures KNN distance by using formula w(X1-X2)kw + (Y1-Y2)kw = Zw\n",
    "- Manhattan Distance: Measures KNN distance by using formula (X1 - Y1) + (X2-Y2) = Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Characteristics of knn model:\n",
    "- Fast to create model because it simply stores data\n",
    "- Slow to predict because many distance calculations\n",
    "- Can require lots of memory if data set is large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoder: \n",
    "One hot encoding makes our training data more useful and expressive, \n",
    "and it can be rescaled easily. By using numeric values, \n",
    "we more easily determine a probability for our values. \n",
    "In particular, one hot encoding is used for our output values, \n",
    "since it provides more nuanced predictions than single labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation: Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The procedure has a single parameter called k that refers to \n",
    "the number of groups that a given data sample is to be split into. \n",
    "As such, the procedure is often called k-fold cross-validation. \n",
    "When a specific value for k is chosen, it may be used in place of \n",
    "k in the reference to the model, \n",
    "such as k=10 becoming 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and y:\n",
    "\n",
    "- X is a matrix of the features values, each column being one feature, \n",
    "and being known values. Each column of X is an independant variable.\n",
    "- y is a vector of the target values, being the \n",
    "values you want to try to predict. y has only one column and is \n",
    "the dependant/target variable. A row in X and y is one data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split:\n",
    "\n",
    "At the begining you will split your data into a train and a test set.</br>\n",
    "So you will have X_train and y_train for the features and target values you will use during the training of your model. And you will have X_test and y_test for the features and target values you will use for the final evaluation of your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underfitting:</br> \n",
    "</br>\n",
    "The counterpart of overfitting, happens when a machine learning model is not complex enough to accurately capture relationships between a datasetâ€™s features and a target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting:</br> \n",
    "</br>\n",
    "Happens when a machine learning model has become too attuned to the data on which it was trained andtherefore loses its applicability to any other dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression:</br>\n",
    "Î²0 is the value of y when x = 0, and Î²1 is the change in y when x increases by 1 unit.\n",
    "Y=B0+B1.X\n",
    "</br>\n",
    "The Residiual: </br>\n",
    "(ğ›½0 + ğ›½1 * ğ‘¥ğ‘œğ‘ğ‘ (ğ‘–)) âˆ’ ğ‘¦ğ‘œğ‘s(i)\n",
    "</br>\n",
    "Mean Squared Error:\n",
    "</br>\n",
    "sum((ğ›½0 + ğ›½1 * ğ‘¥ğ‘œğ‘ğ‘ (ğ‘–)) âˆ’ ğ‘¦ğ‘œğ‘s(i))2\n",
    "</br>\n",
    "Minimum Mean Squared Error:\n",
    "</br>\n",
    "min(sum((ğ›½0 + ğ›½1 * ğ‘¥ğ‘œğ‘ğ‘ (ğ‘–)) âˆ’ ğ‘¦ğ‘œğ‘s(i))2)\n",
    "</br>\n",
    "Cost Function:\n",
    "</br>\n",
    "ğ½ ğ›½0, ğ›½1 =\n",
    "1\n",
    "2ğ‘š\n",
    "ğ‘–=1\n",
    "ğ‘š\n",
    "ğ›½0 + ğ›½1ğ‘¥ğ‘œğ‘ğ‘ \n",
    "(ğ‘–) âˆ’ ğ‘¦ğ‘œğ‘ğ‘ \n",
    "(ğ‘–)\n",
    "2\n",
    "- Use cost function to fit model\n",
    "- Develop multiple models\n",
    "- Compare results and choose best one\n",
    "</br>Other measures of error:\n",
    "- Sum of Squared Error (SSE):\n",
    "- Total Sum of Squares (TSS):\n",
    "- Correlation Coefficient (R2):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling:\n",
    "</br>\n",
    "Feature Scaling is a technique to standardize the independent features present in the data in a fixed range. It is performed during the data pre-processing to handle highly varying magnitudes or values or units. If feature scaling is not done, then a machine learning algorithm tends to weigh greater values, higher and consider smaller values as the lower values, regardless of the unit of the values.\n",
    "\n",
    "Example: If an algorithm is not using the feature scaling method then it can consider the value 3000 meters to be greater than 5 km but thatâ€™s actually not true and in this case, the algorithm will give wrong predictions. So, we use Feature Scaling to bring all values to the same magnitudes and thus, tackle this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Min-Max Normalization: This technique re-scales a feature or observation value with distribution value between 0 and 1.\n",
    "- Standardization: It is a very effective technique which re-scales a feature value so that it has distribution with 0 mean value and variance equals to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Les 3</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting: </br> When a model performs well on training data but\n",
    "doesn't generalize, we are said to be overfitting.(zigzag dots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation:</br> allows us to  compare different machine learning\n",
    "methods and get a sense of how well they will work in practice\n",
    "(ex. knn,logistic regression,support vector machines.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for cross validation:</br>\n",
    "Step 1: Estimate the parameters for the machine learning methods</br>\n",
    "(a.k.a Training the algorithm)</br>\n",
    "Step 2: Evaluate how well the machine learning methods work</br>\n",
    "(a.k.a Testing the algorithm)</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best approach Cross validation: is to split data into 2 1 \n",
    "for training the algorithm and the other to test(xdata,ydata). \n",
    "\n",
    "Bad approach would be to use all data to train. because then\n",
    "there wouldn't be any data left to test the method.\n",
    "\n",
    "Another bad approach would be to use the same data for both\n",
    "training and testing because we need to know how the method\n",
    "will work on data it hasn't trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training error:</br> is the average error that results from using\n",
    "a machine-learning method to predict the response on the training\n",
    "set\n",
    "\n",
    "Test error:</br> is the average error that results from using\n",
    "a machine-learning method to predict on a new observation/datapoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial: means Many Parts/terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization:</br>\n",
    "Regularization is a technique used for \n",
    "tuning the function by adding an additional penalty term \n",
    "in the error function.The additional term controls \n",
    "the excessively fluctuating function such that the coefficients \n",
    "don't take extreme values. (This helps with overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğ½ğ›½0,ğ›½1=1/2ğ‘š sum(ğ‘–=1ğ‘šğ›½0+ğ›½1ğ‘¥ğ‘œğ‘ğ‘ (ğ‘–)âˆ’ğ‘¦ğ‘œğ‘ğ‘ (ğ‘–)2)+ ğœ†ğ‘—=sum(ğ›½ğ‘—2)</br>\n",
    "cost function + ridge regression</br>\n",
    "ğ½ğ›½0,ğ›½1=1/2ğ‘š sum(ğ‘–=1ğ‘šğ›½0+ğ›½1ğ‘¥ğ‘œğ‘ğ‘ (ğ‘–)âˆ’ğ‘¦ğ‘œğ‘ğ‘ (ğ‘–)2)+ ğœ†ğ‘—= sum(|ğ›½ğ‘—|)</br>\n",
    "cost function + lasso regression</br>\n",
    "ğ½ğ›½0,ğ›½1=1/2ğ‘š sum(ğ‘–=1ğ‘šğ›½0+ğ›½1ğ‘¥ğ‘œğ‘ğ‘ (ğ‘–)âˆ’ğ‘¦ğ‘œğ‘ğ‘ (ğ‘–)2)+ ğœ†1=sum(|ğ›½ğ‘—|) + ğœ†2 = sum(ğ›½ğ‘—2)</br>\n",
    "cost function + elastic net regression</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kinds of Regualarization:</br>\n",
    "- Ridge: Penalties all cooeffcients by shrinking,\n",
    "larger coeeficients get penalized heavier thanks to squaring2 \n",
    "(aka l2 norm) \n",
    "- Lasso: Penalty selectively shrinks some coefficients,\n",
    "can be used for feature selection,slower to converge than\n",
    "ridge regression.\n",
    "- Elastic net: Compromises of both ridge and lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso tends to do well if there are a small number of significant parameters and the others are close to zero (ergo: when only a few predictors actually influence the response). Ridge works well if there are many large parameters of about the same value (ergo: when most predictors impact the response)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection:</br>\n",
    "Regularization performs feature selection by shrinking the contribution of features</br>\n",
    "For L1-regularization (lasso), this is accomplished by driving some coefficients to zero.</br>\n",
    "Feature selection can also be performed by removing features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is Feature Selection Important?:</br>\n",
    "- Reducing the number of features is another way to prevent overfitting (similar to regularization)\n",
    "- For some models, fewer features can improve fitting time and/or results\n",
    "- Identifying most critical features can improve model interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent:</br>\n",
    "Tries to find the global minimum.</br>\n",
    "\n",
    "Stochastic Gradient Descent:</br>\n",
    "Takes a random single datapoint cost functions , instead of all the data point cost functions.\n",
    "This makes it faster.</br>\n",
    "ğœ”1=ğœ”0âˆ’ğ›¼ğ›»12ğ›½0+ğ›½1ğ‘¥ğ‘œğ‘ğ‘ (0)âˆ’ğ‘¦ğ‘œğ‘ğ‘ (0)2</br>\n",
    "ğœ”4=ğœ”3âˆ’ğ›¼ğ›»12ğ›½0+ğ›½1ğ‘¥ğ‘œğ‘ğ‘ (3)âˆ’ğ‘¦ğ‘œğ‘ğ‘ (3)2</br>\n",
    "Cost Function: </br>\n",
    "How good your model performs with the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini Batch Gradient Descent:</br>\n",
    "\n",
    "- Perform an update for every ğ‘› training examples</br>\n",
    "<b>Best of both worlds:</b> </br>\n",
    "- Reduced memory relative to \"vanilla\" gradient descent\n",
    "- Less noisy than stochastic gradient descent\n",
    "- Mini batch implementation typically used for neural nets\n",
    "- Batch sizes range from 50â€“256 points\n",
    "- Trade off between batch size and learning rate (ğ›¼)\n",
    "- Tailor learning rate schedule: gradually reduce learning rate during a given epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Les 4</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is used to estimate the dependent variable in case of a change in independent variables. For example, predict the price of houses. Whereas logistic regression is used to calculate the probability of an event. For example, classify if tissue is benign or malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logisticregression.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sigmoid.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"confusionmatrix.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix:</br>\n",
    "We can compare the classification errors with different methods of predictive analysis. </br>\n",
    "For this we can use Cross Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"correct.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"precision.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"recall.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"specifity.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Les 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"overviewclassifier.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"knn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"decisiontrees.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"decisiontreescontinues.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"decisiontreesregressionpred.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"untiltree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"builddecisiontree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Les 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"bagging.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Les 7"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
